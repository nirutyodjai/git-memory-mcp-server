{
  "server": {
    "port": 8080,
    "httpsPort": 8443,
    "host": "0.0.0.0",
    "ssl": {
      "enabled": false,
      "cert": null,
      "key": null
    }
  },
  "upstream": {
    "servers": [
      {
        "id": "code-llama-70b",
        "name": "Code Llama 70B",
        "url": "http://localhost:3001",
        "category": "ai-ml"
      },
      {
        "id": "test-ai-server",
        "name": "Test AI Server",
        "url": "http://localhost:4000",
        "category": "ai-ml"
      }
    ],
    "healthCheck": {
      "enabled": true,
      "interval": 30000,
      "timeout": 5000,
      "path": "/health"
    }
  },
  "loadBalancer": {
    "algorithm": "round-robin",
    "healthCheck": true,
    "failover": true,
    "sticky": false
  },
  "cache": {
    "enabled": true,
    "layers": {
      "memory": {
        "enabled": true,
        "maxSize": 104857600
      },
      "redis": {
        "enabled": false
      },
      "file": {
        "enabled": true,
        "directory": "./cache"
      }
    }
  },
  "security": {
    "authentication": {
      "enabled": true,
      "methods": [
        "jwt",
        "apikey"
      ]
    },
    "rateLimit": {
      "enabled": true,
      "windowMs": 60000,
      "max": 1000
    },
    "cors": {
      "enabled": true,
      "origin": "*"
    }
  },
  "monitoring": {
    "enabled": true,
    "metrics": {
      "enabled": true,
      "retention": 86400000
    },
    "dashboard": {
      "enabled": true,
      "port": 8081
    }
  },
  "websocket": {
    "enabled": true,
    "port": 8082
  },
  "proxy": {
    "timeout": 30000,
    "retries": 3,
    "keepAlive": true
  }
}